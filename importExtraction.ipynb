{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Extraction via include/import directive\n",
    "\n",
    "## Steps\n",
    "1. Recurse through each file of source, use the imports to determine dependency relations, generate TAs\n",
    "2. Save the extracted dependencies to a raw.ta file\n",
    "3. (Optional) Use pipeline to visualize extracted depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/FlinkVersion.java -> flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/ConfigGroup.java -> flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/ConfigGroups.java -> flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/Documentation.java -> flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/ProductionCodeArchitectureBase.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ApiAnnotationRules.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/ProductionCodeArchitectureBase.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ConnectorRules.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/ProductionCodeArchitectureBase.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/TableApiRules.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ApiAnnotationRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/Experimental.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ApiAnnotationRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/Internal.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ApiAnnotationRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ApiAnnotationRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/PublicEvolving.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ApiAnnotationRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/VisibleForTesting.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ConnectorRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/ConnectorRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/PublicEvolving.java\n",
      "flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/architecture/rules/TableApiRules.java -> flink-1.17.1/flink-architecture-tests/flink-architecture-tests-production/src/main/java/org/apache/flink/annotation/Public.java\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate dependencies\n",
    "import os\n",
    "\n",
    "src = \".\\\\flink-1.17.1\"\n",
    "dependencies = []\n",
    "\n",
    "\n",
    "def package_to_path(parent_module, package_name):\n",
    "  return parent_module + package_name.replace(\".\", \"\\\\\") + \".java\"\n",
    "\n",
    "\n",
    "def process_line(file_path, line):\n",
    "  # Example: \n",
    "  # line = import org.apache.flink.api.common.functions.MapFunction;\n",
    "  # first need to remove the ; at end and split by space\n",
    "  dependency = line.split(\" \")[1].strip().replace(\";\", \"\")\n",
    "\n",
    "  # Example:\n",
    "  # file_path = .\\flink-1.17.1\\flink-core\\src\\main\\java\\org\\apache\\flink\\api\\common\\functions\\MapFunction.java\n",
    "  # want to only get the parent directory up until /java/ at which point things will be scoped by package (org.apache.flink.*)\n",
    "  parent_module = file_path.split(\"\\\\java\\\\\")[0] + \"\\\\java\\\\\"\n",
    "\n",
    "  # now we can convert the package to a path and add the tuple to our list\n",
    "  dependency = package_to_path(parent_module, dependency)\n",
    "  dependencies.append((file_path[2:].replace(\"\\\\\", \"/\"), dependency[2:].replace(\"\\\\\", \"/\")))\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "  with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if not line.startswith(\"import\") or not \"org.apache\" in line:\n",
    "            continue\n",
    "        # this is a static import; not sure if we care about them or if we should just remove the static keyword\n",
    "        # for now we will just ignore them\n",
    "        if \"static\" in line: \n",
    "          continue\n",
    "        process_line(file_path, line)\n",
    "\n",
    "\n",
    "def generate_dependencies():\n",
    "  for dir_path, _, file_names in os.walk(src):\n",
    "    for file_name in file_names:\n",
    "      if file_name.endswith(\".java\") and not \"\\\\test\\\\\" in dir_path:\n",
    "        process_file(dir_path + \"\\\\\" + file_name)\n",
    "\n",
    "\n",
    "generate_dependencies()\n",
    "# print out the dependencies to verify they are correct\n",
    "\n",
    "limit = 15\n",
    "for file_path, dependency in dependencies:\n",
    "  print(file_path + \" -> \" + dependency)\n",
    "\n",
    "  limit -= 1\n",
    "  if limit == 0:\n",
    "    break\n",
    "\n",
    "print(len(dependencies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate the raw.ta file\n",
    "raw_ta_output = \"./visualize/source/dependencies.raw.ta\"\n",
    "\n",
    "with open(raw_ta_output, \"w+\") as f:\n",
    "  # first generate all the concrete instances\n",
    "  f.write(\"FACT TUPLE : \\n\")\n",
    "\n",
    "  unique_file_paths = set(file_path for file_path, _ in dependencies)\n",
    "\n",
    "  for file_path in unique_file_paths:\n",
    "    f.write(f\"$INSTANCE {file_path} cFile\\n\")\n",
    "\n",
    "  # now add in all the dependencies\n",
    "  for file_path, dependency in dependencies:\n",
    "    f.write(f\"cLinks {file_path} {dependency}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted flink_UnderstandFileDependency.raw.ta\n",
      "Successfully deleted flink_UnderstandFileDependency.ls.ta\n",
      "Successfully deleted flink_UnderstandFileDependency.contain\n",
      "Create Containment Output:\n",
      "\n",
      "c:\\Users\\k899e\\projects\\school\\4314\\a4\\visualize>java -Xms256M -Xmx1024M -classpath ql.jar ca.uwaterloo.cs.ql.Main addcontain.ql flink_UnderstandFileDependency.contain flink_UnderstandFileDependency.raw.ta flink_UnderstandFileDependency.con.ta \n",
      "  Error[addcontain.ql]: extra files included in contain\n",
      "     Channel.ss\n",
      "     CheckpointCoordinator.ss\n",
      "     Dispatcher.ss\n",
      "     Entrypoint.ss\n",
      "     ExecutionGraph.ss\n",
      "     FlinkClients.ss\n",
      "     Hooks.ss\n",
      "     JobGraph.ss\n",
      "     JobManager.ss\n",
      "     JobMaster.ss\n",
      "     Metadata.ss\n",
      "     ResourceManager.ss\n",
      "     Security.ss\n",
      "     State.ss\n",
      "     TaskExecutor.ss\n",
      "     TaskManager.ss\n",
      "\n",
      "c:\\Users\\k899e\\projects\\school\\4314\\a4\\visualize>type schema.asv.ta flink_UnderstandFileDependency.con.ta  1>flink_UnderstandFileDependency.ls.ta \n",
      "\n",
      "\n",
      "Create Containment Errors:\n",
      "The system cannot find the file specified.\n",
      "Error occurred while processing: schema.asv.ta.\n",
      "The system cannot find the file specified.\n",
      "Error occurred while processing: flink_UnderstandFileDependency.con.ta.\n",
      "\n",
      "\n",
      "\n",
      "c:\\Users\\k899e\\projects\\school\\4314\\a4\\visualize>java  -Xms256M -Xmx1024M -jar lseditor-7.3.13.jar flink_UnderstandFileDependency.con.ta \n",
      "Load state from C:\\Users\\k899e\\lsedit.ini\n",
      "\u0007Load failed (flink_UnderstandFileDependency.con.ta (The system cannot find the file specified)) for: flink_UnderstandFileDependency.con.ta\n",
      "Saving state in C:\\Users\\k899e\\lsedit.ini\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Step 3: Run pipeline\n",
    "!cd visualize && python ./pipeline.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
